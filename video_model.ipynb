{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96f9f02",
   "metadata": {},
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "We are using the Face Forensics++ (FF++) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce6fbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/Live_Projects/History_of_Man/proactives_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.5G/22.5G [23:54<00:00, 16.8MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/jordan/.cache/kagglehub/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34863886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CSV file found in dataset directory: /Users/jordan/.cache/kagglehub/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset/versions/1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004440c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real folder mp4 count: 363\n",
      "Fake folder mp4 count: 3068\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#store the paths to the real and fake images in an env file\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "real_path = os.getenv('REAL_PATH')\n",
    "fake_path = os.getenv('DEEPFAKE_PATH')\n",
    "\n",
    "def count_mp4_files(folder):\n",
    "    mp4_count = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        mp4_count += sum(1 for f in files if f.endswith('.mp4'))\n",
    "    return mp4_count\n",
    "\n",
    "real_mp4_count = count_mp4_files(real_path)\n",
    "fake_mp4_count = count_mp4_files(fake_path)\n",
    "\n",
    "print(f'Real folder mp4 count: {real_mp4_count}')\n",
    "print(f'Fake folder mp4 count: {fake_mp4_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14d1c8",
   "metadata": {},
   "source": [
    "Use the EfficientNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56bcc278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def get_efficientnet_feature_extractor():\n",
    "    \"\"\"\n",
    "    Returns an EfficientNetB0 model that outputs feature vectors instead of class predictions.\n",
    "    \"\"\"\n",
    "    # Load EfficientNetB0 without the top classification layer\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
    "    # The output will be the global average pooled features\n",
    "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    return feature_extractor\n",
    "\n",
    "def extract_face_features(face_images, feature_extractor):\n",
    "    \"\"\"\n",
    "    Given a batch of face images, returns their EfficientNet feature vectors.\n",
    "    face_images: numpy array of shape (batch_size, height, width, channels)\n",
    "    feature_extractor: model returned by get_efficientnet_feature_extractor()\n",
    "    \"\"\"\n",
    "    # EfficientNet expects images scaled to [0, 255] and size 224x224\n",
    "    # You may need to preprocess your images accordingly\n",
    "    features = feature_extractor.predict(face_images)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71ba8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def save_first_210_cropped_faces(video_path, output_dir, yolo_model_path='yolov8n.pt', conf=0.5, save_images=False):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if save_images:\n",
    "        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    \n",
    "    model = YOLO(yolo_model_path)\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "    while frame_count < 210:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Could not read frame {frame_count}\")\n",
    "            break\n",
    "        \n",
    "        results = model.predict(source=frame, conf=conf, classes=0, verbose=False)\n",
    "        \n",
    "        # Find the largest face in this frame\n",
    "        largest_face = None\n",
    "        largest_area = 0\n",
    "        \n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                if area > largest_area:\n",
    "                    largest_area = area\n",
    "                    largest_face = (x1, y1, x2, y2)\n",
    "        \n",
    "        # Save only the largest face if found\n",
    "        if largest_face:\n",
    "            x1, y1, x2, y2 = largest_face\n",
    "            face = frame[y1:y2, x1:x2]\n",
    "            face_resized = cv2.resize(face, (224, 224))\n",
    "            face_scaled = face_resized.astype(np.float32) / 127.5 - 1.0\n",
    "            \n",
    "            # Save as numpy array for EfficientNet\n",
    "            np.save(os.path.join(output_dir, f\"face_{frame_count:04d}.npy\"), face_scaled)\n",
    "            \n",
    "            # Optionally save as image for visualization\n",
    "            if save_images:\n",
    "                # Convert back to 0-255 range for image saving\n",
    "                face_image = ((face_scaled + 1.0) * 127.5).astype(np.uint8)\n",
    "                cv2.imwrite(os.path.join(output_dir, 'images', f\"face_{frame_count:04d}.png\"), face_image)\n",
    "            \n",
    "            saved_count += 1\n",
    "        else:\n",
    "            print(f\"No face detected in frame {frame_count}\")\n",
    "        \n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    print(f\"Saved {saved_count} cropped faces to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: /Users/jordan/.cache/kagglehub/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset/versions/1/DFD_manipulated_sequences/DFD_manipulated_sequences/13_20__walking_down_indoor_hall_disgust__EV1V4ZQV.mp4\n",
      "Saved 210 cropped faces to cropped_faces_output\n",
      "Saved 210 cropped faces to cropped_faces_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the path to the fake videos folder from your .env\n",
    "fake_path = os.getenv('DEEPFAKE_PATH')\n",
    "\n",
    "# List all mp4 files in the fake folder\n",
    "fake_videos = [f for f in os.listdir(fake_path) if f.endswith('.mp4')]\n",
    "\n",
    "if fake_videos:\n",
    "    first_video = fake_videos[0]\n",
    "    video_path = os.path.join(fake_path, first_video)\n",
    "    output_dir = 'example_output'  # Change this to your desired output folder\n",
    "\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    save_first_210_cropped_faces(video_path, output_dir, save_images=True)\n",
    "else:\n",
    "    print(\"No fake videos found in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519c408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proactives_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
