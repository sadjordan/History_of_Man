{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96f9f02",
   "metadata": {},
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "We are using the Face Forensics++ (FF++) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6fbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/Desktop/Live_Projects/History_of_Man/proactives_venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.5G/22.5G [23:54<00:00, 16.8MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/jordan/.cache/kagglehub/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34863886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CSV file found in dataset directory: /Users/jordan/.cache/kagglehub/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset/versions/1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004440c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real folder mp4 count: 363\n",
      "Fake folder mp4 count: 3068\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#store the paths to the real and fake images in an env file\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "real_path = os.getenv('REAL_PATH')\n",
    "fake_path = os.getenv('DEEPFAKE_PATH')\n",
    "\n",
    "def count_mp4_files(folder):\n",
    "    mp4_count = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        mp4_count += sum(1 for f in files if f.endswith('.mp4'))\n",
    "    return mp4_count\n",
    "\n",
    "real_mp4_count = count_mp4_files(real_path)\n",
    "fake_mp4_count = count_mp4_files(fake_path)\n",
    "\n",
    "print(f'Real folder mp4 count: {real_mp4_count}')\n",
    "print(f'Fake folder mp4 count: {fake_mp4_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14d1c8",
   "metadata": {},
   "source": [
    "Use the EfficientNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bcc278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def get_efficientnet_feature_extractor():\n",
    "    \"\"\"\n",
    "    Returns an EfficientNetB0 model that outputs feature vectors instead of class predictions.\n",
    "    \"\"\"\n",
    "    # Load EfficientNetB0 without the top classification layer\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
    "    # The output will be the global average pooled features\n",
    "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    return feature_extractor\n",
    "\n",
    "def extract_face_features(face_images, feature_extractor):\n",
    "    \"\"\"\n",
    "    Given a batch of face images, returns their EfficientNet feature vectors.\n",
    "    face_images: numpy array of shape (batch_size, height, width, channels)\n",
    "    feature_extractor: model returned by get_efficientnet_feature_extractor()\n",
    "    \"\"\"\n",
    "    # EfficientNet expects images scaled to [0, 255] and size 224x224\n",
    "    # You may need to preprocess your images accordingly\n",
    "    features = feature_extractor.predict(face_images)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa33df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba8d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proactives_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
